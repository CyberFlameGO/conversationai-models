{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import getpass\n",
    "from IPython.display import display\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_export.dataset import Dataset, Model\n",
    "from utils_export import utils_cloudml\n",
    "from utils_export import utils_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster to access GCS file:\n",
    "# https://github.com/tensorflow/tensorflow/issues/15530\n",
    "os.environ['GCS_READ_CACHE_MAX_SIZE_MB'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/msushkov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text, lowercase=True):\n",
    "  \"\"\"Converts text to a list of words.\n",
    "\n",
    "  Args:\n",
    "    text: piece of text to tokenize (string).\n",
    "    lowercase: whether to include lowercasing in preprocessing (bool).\n",
    "\n",
    "  Returns:\n",
    "    A list of strings (words).\n",
    "  \"\"\"\n",
    "  words = nltk.word_tokenize(text.decode('utf-8'))\n",
    "  if lowercase:\n",
    "    words = [w.lower() for w in words]\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_input_fn(dataset_path,\n",
    "                       model_text_feature,\n",
    "                       dataset_text_feature,\n",
    "                       data_label,\n",
    "                       tokenizer_fn,\n",
    "                       label_data_type=tf.float32,\n",
    "                       max_n_examples=None,\n",
    "                       random_filter_keep_rate=1.0):\n",
    "    \"\"\"Returns a test input function.\n",
    "    \n",
    "    Args:\n",
    "      dataset_path (str): Path to dataset.\n",
    "      model_text_feature (str): The feature column corresponding to the\n",
    "        text input the model expects.\n",
    "      dataset_text_feature (str): The name of the text feature of the dataset.\n",
    "      data_label (str): The output label for the dataset.\n",
    "      tokenizer_fn: Tokenizer function (str -> list).\n",
    "      max_n_examples (int): How many examples to evaluate on.\n",
    "      random_filter_keep_rate (float): Filter out test examples with this probability.\n",
    "\n",
    "    Returns:\n",
    "      Test input function.\n",
    "    \"\"\"\n",
    "    decoding_input_features = {\n",
    "      dataset_text_feature: tf.FixedLenFeature([], dtype=tf.string),\n",
    "      data_label: tf.FixedLenFeature([], dtype=label_data_type)\n",
    "    }\n",
    "\n",
    "    def test_input_fn(max_n_examples=max_n_examples,\n",
    "                      random_filter_keep_rate=random_filter_keep_rate):\n",
    "        \"\"\"Test input function.\n",
    "        \n",
    "        Args:\n",
    "          max_n_examples (int): How many examples to evaluate on.\n",
    "          random_filter_keep_rate (float): Filter out test examples with this probability.\n",
    "          \n",
    "        Returns:\n",
    "          DataFrame with the results.\n",
    "        \"\"\"\n",
    "        res = utils_tfrecords.decode_tf_records_to_pandas(\n",
    "            decoding_input_features,\n",
    "            dataset_path,\n",
    "            max_n_examples,\n",
    "            random_filter_keep_rate)\n",
    "        if not tokenizer_fn:\n",
    "            tok = lambda x: [x]\n",
    "            res[model_text_feature] = list(map(tok, res[dataset_text_feature]))\n",
    "        else:\n",
    "            res[model_text_feature] = list(map(tokenizer_fn, res[dataset_text_feature]))\n",
    "        res = res.rename(columns={ data_label: 'label' })\n",
    "        res['label'] = list(map(lambda x: bool(round(x)), list(res['label'])))\n",
    "        final = res.copy(deep=True)\n",
    "        return final\n",
    "\n",
    "    return test_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results_df, model_names, print_pr_curve=False):\n",
    "    \"\"\"Print the classification results.\n",
    "    \n",
    "    Args:\n",
    "      results_df: DataFrame with the results.\n",
    "      model_names: List of strings representing the models for which we have results.\n",
    "    \"\"\"\n",
    "    labels = results_df['label']\n",
    "    for _model in model_names:\n",
    "        print(_model)\n",
    "        model_preds = results_df[_model]\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(labels, model_preds)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        recalls, precisions, thr = metrics.precision_recall_curve(labels, model_preds)\n",
    "        pr_auc = metrics.auc(precisions, recalls)\n",
    "        model_preds_binary = (model_preds > 0.5).astype(np.int_)\n",
    "        f1 = metrics.f1_score(labels, model_preds_binary)\n",
    "        print('\\tROC AUC: {}'.format(roc_auc))\n",
    "        print('\\tPR AUC: {}'.format(pr_auc))\n",
    "        print('\\tF1: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'conversationai-models'\n",
    "SENTENCE_KEY = 'comment_key' #Input key\n",
    "\n",
    "# Pattern for path of tf_records\n",
    "OUTPUT_DIR_BASE = os.path.join(\n",
    "    'gs://conversationai-models',\n",
    "    getpass.getuser(),\n",
    "    'tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models on Civil Comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAME_PREDICTION_MODEL = 'toxicity/logistic'\n",
    "DATASET = 'gs://conversationai-models/resources/civil_comments_data/train_eval_test/test-*.tfrecord'\n",
    "DATA_LABEL = 'toxicity'\n",
    "DATASET_TEXT_FEATURE='comment_text'\n",
    "\n",
    "# Pattern for path of tf_records\n",
    "OUTPUT_DIR = os.path.join(OUTPUT_DIR_BASE, 'civil_comments_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN, GRU Attention Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'tokens'\n",
    "MODEL_NAMES = [\n",
    "    'tf_cnn_civil_comments_glove:v_20190219_185541',\n",
    "    'tf_gru_attention_civil_comments_glove:v_20190219_185619',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR)\n",
    "test_dataset.load_data(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "civil_comments_test_df = test_dataset.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_civil_comments_glove:v_20190219_185541\n",
      "\tROC AUC: 0.9573435242534393\n",
      "\tPR AUC: 0.6729934425219886\n",
      "tf_gru_attention_civil_comments_glove:v_20190219_185619\n",
      "\tROC AUC: 0.9649161132104584\n",
      "\tPR AUC: 0.7486011745102973\n"
     ]
    }
   ],
   "source": [
    "print_results(civil_comments_test_df, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Hub Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'text'\n",
    "MODEL_NAMES = [\n",
    "    'tf_hub_classifier_civil_comments:v20190322_142141_21201_1553344552',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR)\n",
    "test_dataset.load_data(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "civil_comments_hub_df = test_dataset.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_hub_classifier_civil_comments:v20190322_142141_21201_1553344552\n",
      "\tROC AUC: 0.9595451744696132\n",
      "\tPR AUC: 0.7429338592289392\n"
     ]
    }
   ],
   "source": [
    "print_results(civil_comments_hub_df, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models on Toxicity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAME_PREDICTION_MODEL = 'frac_neg/logistic'\n",
    "DATASET = 'gs://conversationai-models/resources/toxicity_data/toxicity_q42017_test.tfrecord'\n",
    "DATA_LABEL = 'frac_neg'\n",
    "DATASET_TEXT_FEATURE='comment_text'\n",
    "\n",
    "# Pattern for path of tf_records\n",
    "OUTPUT_DIR = os.path.join(OUTPUT_DIR_BASE, 'toxicity_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN, GRU Attention Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'tokens'\n",
    "MODEL_NAMES = [\n",
    "    'tf_cnn_toxicity_glove:v_20190219_185532',\n",
    "    'tf_gru_attention_toxicity_glove:v_20190219_185516',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR)\n",
    "test_dataset.load_data(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_test_df1 = test_dataset.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_toxicity_glove:v_20190219_185532\n",
      "\tROC AUC: 0.951760553925346\n",
      "\tPR AUC: 0.8740274773143215\n",
      "tf_gru_attention_toxicity_glove:v_20190219_185516\n",
      "\tROC AUC: 0.9543916575133977\n",
      "\tPR AUC: 0.8814208812923074\n"
     ]
    }
   ],
   "source": [
    "print_results(toxicity_test_df1, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Hub Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'text'\n",
    "MODEL_NAMES = [\n",
    "    'tf_hub_classifier_toxicity:v20190322_142740_24239_1553555427',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR)\n",
    "test_dataset.load_data(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_test_df2 = test_dataset.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_hub_classifier_toxicity:v20190322_142740_24239_1553555427\n",
      "\tROC AUC: 0.9270843170934745\n",
      "\tPR AUC: 0.8155815559085313\n"
     ]
    }
   ],
   "source": [
    "print_results(toxicity_test_df2, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models on Many Communities dataset (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAME_PREDICTION_MODEL = 'removed/logistic'\n",
    "DATASET = 'gs://conversationai-models/resources/transfer_learning_data/many_communities/20181105_answers_all_columns_nthain.tfrecord'\n",
    "DATA_LABEL = 'removed'\n",
    "DATASET_TEXT_FEATURE='comment_text'\n",
    "\n",
    "# Pattern for path of tf_records\n",
    "OUTPUT_DIR = os.path.join(OUTPUT_DIR_BASE, 'many_communities_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN, GRU Attention Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'tokens'\n",
    "MODEL_NAMES = [\n",
    "    'tf_cnn_many_communities_glove:v_20190219_185551_gpu_p100_4',\n",
    "    #'tf_gru_attention_many_communities:v20190322_142800_507893_1556085643',\n",
    "    #'tf_gru_attention_many_communities:v20190315_161037_23271_1555129264',\n",
    "    'tf_gru_attention_many_communities:v20190705_004839_507000_1562364428_gpu_p100_4',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer, label_data_type=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR)\n",
    "test_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_communities_test_df = test_dataset.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_many_communities_glove:v_20190219_185551\n",
      "\tROC AUC: 0.7476941464055139\n",
      "\tPR AUC: 0.07604839414024091\n",
      "tf_gru_attention_many_communities:v20190315_161037_23271_1555129264\n",
      "\tROC AUC: 0.7215269560475308\n",
      "\tPR AUC: 0.06656538517176142\n"
     ]
    }
   ],
   "source": [
    "print_results(many_communities_test_df, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Hub Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'text'\n",
    "MODEL_NAMES = [\n",
    "    'tf_hub_classifier_many_communities:v20190219_185602_316000_1553563221_gpu_v100_4',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None, label_data_type=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR)\n",
    "test_dataset.load_data(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_communities_tfhub_test_df = test_dataset.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(many_communities_tfhub_test_df, MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models on Many Communities subset (adapted for few-shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAME_PREDICTION_MODEL = 'label/logistic'\n",
    "DATASET_VALID = 'gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/validation_query..tfrecord'\n",
    "DATASET_TEST = 'gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/test_query..tfrecord'\n",
    "DATA_LABEL = 'label'\n",
    "DATASET_TEXT_FEATURE='text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pessimistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern for path of tf_records\n",
    "OUTPUT_DIR_VALID = os.path.join(OUTPUT_DIR_BASE, 'many_communities_40_per_8_shot/pessimistic/valid')\n",
    "OUTPUT_DIR_TEST = os.path.join(OUTPUT_DIR_BASE, 'many_communities_40_per_8_shot/pessimistic/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN, GRU Attention Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'tokens'\n",
    "MODEL_NAMES = [\n",
    "    'tf_cnn_many_communities_40_per_8_shot_pessimistic:v20190723_110543_2800_1563906804_gpu_k80_1',\n",
    "    'tf_gru_attention_many_communities_40_per_8_shot_pessimistic:v20190723_110533_4400_1563906956_gpu_k80_1',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "valid_input_fn = make_test_input_fn(\n",
    "    DATASET_VALID, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer, label_data_type=tf.int64)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET_TEST, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer, label_data_type=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "valid_dataset = Dataset(valid_input_fn, OUTPUT_DIR_VALID)\n",
    "valid_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR_TEST)\n",
    "test_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "valid_dataset.add_model_prediction_to_data(model, recompute_predictions=True)\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_many_communities_40_per_8_shot_pessimistic:v20190723_110543_2800_1563906804_gpu_k80_1\n",
      "\tROC AUC: 0.8233381391772395\n",
      "\tPR AUC: 0.8062951511107903\n",
      "\tF1: 0.7607565011820331\n",
      "tf_gru_attention_many_communities_40_per_8_shot_pessimistic:v20190723_110533_4400_1563906956_gpu_k80_1\n",
      "\tROC AUC: 0.8303615196078432\n",
      "\tPR AUC: 0.8125045070656154\n",
      "\tF1: 0.7703703703703705\n"
     ]
    }
   ],
   "source": [
    "print_results(valid_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_many_communities_40_per_8_shot_pessimistic:v20190723_110543_2800_1563906804_gpu_k80_1\n",
      "\tROC AUC: 0.7981477681641835\n",
      "\tPR AUC: 0.7900106468171257\n",
      "\tF1: 0.7378091872791519\n",
      "tf_gru_attention_many_communities_40_per_8_shot_pessimistic:v20190723_110533_4400_1563906956_gpu_k80_1\n",
      "\tROC AUC: 0.8074846866462235\n",
      "\tPR AUC: 0.7951370231895221\n",
      "\tF1: 0.7507100720996286\n"
     ]
    }
   ],
   "source": [
    "print_results(test_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-Hub Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'text'\n",
    "MODEL_NAMES = [\n",
    "    'tf_hub_classifier_many_communities_40_per_8_shot_pessimistic:v20190723_110557_2600_1563911706_gpu_k80_1',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "valid_input_fn = make_test_input_fn(\n",
    "    DATASET_VALID, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None, label_data_type=tf.int64)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET_TEST, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None, label_data_type=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "valid_dataset = Dataset(valid_input_fn, OUTPUT_DIR_VALID)\n",
    "valid_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR_TEST)\n",
    "test_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "valid_dataset.add_model_prediction_to_data(model, recompute_predictions=True)\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_hub_classifier_many_communities_40_per_8_shot_pessimistic:v20190723_110557_2600_1563911706_gpu_k80_1\n",
      "\tROC AUC: 0.8612435121107267\n",
      "\tPR AUC: 0.851153195076283\n",
      "\tF1: 0.7937575030012005\n"
     ]
    }
   ],
   "source": [
    "print_results(valid_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_hub_classifier_many_communities_40_per_8_shot_pessimistic:v20190723_110557_2600_1563911706_gpu_k80_1\n",
      "\tROC AUC: 0.8434673869262717\n",
      "\tPR AUC: 0.8326080326940988\n",
      "\tF1: 0.779380468195791\n"
     ]
    }
   ],
   "source": [
    "print_results(test_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern for path of tf_records\n",
    "OUTPUT_DIR_VALID = os.path.join(OUTPUT_DIR_BASE, 'many_communities_40_per_8_shot/optimistic/valid')\n",
    "OUTPUT_DIR_TEST = os.path.join(OUTPUT_DIR_BASE, 'many_communities_40_per_8_shot/optimistic/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN, GRU Attention Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'tokens'\n",
    "MODEL_NAMES = [\n",
    "    'tf_cnn_many_communities_40_per_8_shot_optimistic:v20190723_110516_4200_1563906960_gpu_k80_1',\n",
    "    'tf_gru_attention_many_communities_40_per_8_shot_optimistic:v20190723_110524_4200_1563907005_gpu_k80_1',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "valid_input_fn = make_test_input_fn(\n",
    "    DATASET_VALID, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer, label_data_type=tf.int64)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET_TEST, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, tokenizer, label_data_type=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "valid_dataset = Dataset(valid_input_fn, OUTPUT_DIR_VALID)\n",
    "valid_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR_TEST)\n",
    "test_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "valid_dataset.add_model_prediction_to_data(model, recompute_predictions=True)\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_many_communities_40_per_8_shot_optimistic:v20190723_110516_4200_1563906960_gpu_k80_1\n",
      "\tROC AUC: 0.8304709727028066\n",
      "\tPR AUC: 0.8191225889787218\n",
      "\tF1: 0.7564259485924112\n",
      "tf_gru_attention_many_communities_40_per_8_shot_optimistic:v20190723_110524_4200_1563907005_gpu_k80_1\n",
      "\tROC AUC: 0.8293254998077663\n",
      "\tPR AUC: 0.8181913933482414\n",
      "\tF1: 0.7652214022140222\n"
     ]
    }
   ],
   "source": [
    "print_results(valid_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_cnn_many_communities_40_per_8_shot_optimistic:v20190723_110516_4200_1563906960_gpu_k80_1\n",
      "\tROC AUC: 0.8043942295635125\n",
      "\tPR AUC: 0.79754755517453\n",
      "\tF1: 0.7305737109658679\n",
      "tf_gru_attention_many_communities_40_per_8_shot_optimistic:v20190723_110524_4200_1563907005_gpu_k80_1\n",
      "\tROC AUC: 0.8156875904836816\n",
      "\tPR AUC: 0.8081941065311745\n",
      "\tF1: 0.7558876811594204\n"
     ]
    }
   ],
   "source": [
    "print_results(test_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-Hub Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TEXT_FEATURE = 'text'\n",
    "MODEL_NAMES = [\n",
    "    'tf_hub_classifier_many_communities_40_per_8_shot_optimistic:v20190723_102555_3600_1563909345_gpu_k80_1',\n",
    "]\n",
    "\n",
    "model_input_spec = {\n",
    "    MODEL_TEXT_FEATURE: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "valid_input_fn = make_test_input_fn(\n",
    "    DATASET_VALID, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None, label_data_type=tf.int64)\n",
    "\n",
    "test_input_fn = make_test_input_fn(\n",
    "    DATASET_TEST, MODEL_TEXT_FEATURE, DATASET_TEXT_FEATURE,\n",
    "    DATA_LABEL, None, label_data_type=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "valid_dataset = Dataset(valid_input_fn, OUTPUT_DIR_VALID)\n",
    "valid_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set seed before loading data to be able to reload same data in the future\n",
    "random.seed(2018)\n",
    "\n",
    "test_dataset = Dataset(test_input_fn, OUTPUT_DIR_TEST)\n",
    "test_dataset.load_data(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "valid_dataset.add_model_prediction_to_data(model, recompute_predictions=True)\n",
    "test_dataset.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_hub_classifier_many_communities_40_per_8_shot_optimistic:v20190723_102555_3600_1563909345_gpu_k80_1\n",
      "\tROC AUC: 0.8680750192233757\n",
      "\tPR AUC: 0.8623373414090059\n",
      "\tF1: 0.7900994904149479\n"
     ]
    }
   ],
   "source": [
    "print_results(valid_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_hub_classifier_many_communities_40_per_8_shot_optimistic:v20190723_102555_3600_1563909345_gpu_k80_1\n",
      "\tROC AUC: 0.8526337876041631\n",
      "\tPR AUC: 0.8481017558154519\n",
      "\tF1: 0.784984556901877\n"
     ]
    }
   ],
   "source": [
    "print_results(test_dataset.show_data(), MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_results_files(parent_dir):\n",
    "    \"\"\"Gets the paths of all results files that are in parent_dir.\"\"\"\n",
    "    file_list = []\n",
    "    for subdirectory, _, files in tf.gfile.Walk(parent_dir):\n",
    "        [file_list.append(os.path.join(parent_dir, fname)) for fname in files]\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_predictions(pred_file, is_test=False):\n",
    "    \"\"\"Load the CSV file with predictions and labels.\"\"\"\n",
    "    model_predictions = None\n",
    "    labels = None\n",
    "    communities = None\n",
    "    names = ['label', 'pred', 'community']\n",
    "    if is_test:\n",
    "        names = ['community', 'label', 'pred']\n",
    "    with file_io.FileIO(pred_file, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None, names=names)\n",
    "        labels = df['label'].values\n",
    "        model_predictions = df['pred'].values\n",
    "        communities = df['community'].values\n",
    "    return labels, model_predictions, communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(precisions, recalls, identifier=None):\n",
    "    \"\"\"Plots the Precision/Recall curve.\n",
    "    Args:\n",
    "      precisions: Precisions at all score thresholds.\n",
    "      recalls: Recalls at all score thresholds.\n",
    "      identifier: Optional string indicating what this curve is.\n",
    "    \"\"\"\n",
    "    precision_recall_auc = metrics.auc(recalls, precisions)\n",
    "    plt.figure()\n",
    "    step_kwargs = ({\n",
    "        'step': 'post'\n",
    "    } if 'step' in fixes.signature(plt.fill_between).parameters else {})\n",
    "    plt.step(recalls, precisions, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recalls, precisions, alpha=0.2, color='b', **step_kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1])\n",
    "    if identifier:\n",
    "        plt.title('PR curve for %s (AUC = %.2f).' % (\n",
    "            identifier, precision_recall_auc))\n",
    "    else:\n",
    "        plt.title('PR curve (AUC = %.2f).' % precision_recall_auc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_dir(results_dir, is_test=False):\n",
    "    files = get_list_results_files(results_dir)\n",
    "    for file_path in files:\n",
    "        curr_trial_name = os.path.basename(file_path)\n",
    "        print(curr_trial_name)\n",
    "        labels, model_preds, communities = load_csv_predictions(file_path, is_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(labels, model_preds)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        precisions, recalls, thr = metrics.precision_recall_curve(labels, model_preds)\n",
    "        pr_auc = metrics.auc(recalls, precisions)\n",
    "        model_preds_binary = (model_preds > 0.5).astype(np.int_)\n",
    "        f1 = metrics.f1_score(labels, model_preds_binary)\n",
    "        print('\\tROC AUC: {}'.format(roc_auc))\n",
    "        print('\\tPR AUC: {}'.format(pr_auc))\n",
    "        print('\\tF1: {}'.format(f1))\n",
    "        plot_pr_curve(precisions, recalls, curr_trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_CNN_VALID_RESULTS_DIR = \"gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/results/tf_cnn/validation\"\n",
    "TF_GRU_VALID_RESULTS_DIR = \"gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/results/tf_gru_attention/validation\"\n",
    "TF_HUB_VALID_RESULTS_DIR = \"gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/results/tf_hub_classifier/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_from_dir(TF_CNN_VALID_RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_from_dir(TF_GRU_VALID_RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_from_dir(TF_HUB_VALID_RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_CNN_TEST_RESULTS_DIR = \"gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/results/tf_cnn/test\"\n",
    "TF_GRU_TEST_RESULTS_DIR = \"gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/results/tf_gru_attention/test\"\n",
    "TF_HUB_TEST_RESULTS_DIR = \"gs://conversationai-models/resources/transfer_learning_data/many_communities_40_per_8_shot/results/tf_hub_classifier/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_from_dir(TF_CNN_TEST_RESULTS_DIR, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_from_dir(TF_GRU_TEST_RESULTS_DIR, is_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_from_dir(TF_HUB_TEST_RESULTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
