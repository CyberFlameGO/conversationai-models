{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YibCLoSLRHp"
   },
   "source": [
    "Copyright 2018 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMykUGMauh9b"
   },
   "source": [
    "# Evaluation code\n",
    "\n",
    "\n",
    "__Disclaimer__\n",
    "*   This notebook contains experimental code, which may be changed without notice.\n",
    "*   The ideas here are some ideas relevant to fairness - they are not the whole story!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook intends to evaluate a list of models on two dimensions:\n",
    "- \"Performance\": How well the model perform to classify the data (intended bias). Currently, we use the AUC.\n",
    "- \"Bias\": How much bias does the model contain (unintended bias). Currently, we use the pinned auc.\n",
    "\n",
    "This script takes the following steps:\n",
    "\n",
    "- Write input function to generate 2 datasets:\n",
    "    - a \"performance dataset\" which will be used for the first set of metrics. This dataset is supposed to be similar format to the training data (contain a text and a label).\n",
    "    - a \"bias dataset\" which will be used for the second set of metrics. This data contains a text, a label but also some subgroup information to evaluate the unintended bias on.\n",
    "- Runs predictions with the export_utils.\n",
    "- Evaluate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/fprost/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import getpass\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# import googleapiclient.discovery as discovery\n",
    "# import googleapiclient.errors as errors\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils_export.dataset import Dataset, Model\n",
    "from utils_export import utils_cloudml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GCS_READ_CACHE_MAX_SIZE_MB'] = '0' #Faster to access GCS file + https://github.com/tensorflow/tensorflow/issues/15530"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "PROJECT_NAME = 'wikidetox'\n",
    "\n",
    "# Information about deployed model.\n",
    "MODEL_NAMES = ['tf_gru_attention:v_20180823_133625']\n",
    "TEXT_FEATURE_NAME = 'comment_text' #Input text\n",
    "SENTENCE_KEY = 'comment_key' #Input key\n",
    "LABEL_NAME_PREDICTION_MODEL = 'frac_neg/logistic' # Output prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Creating input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text, lowercase=True):\n",
    "  \"\"\"Converts text to a list of words.\n",
    "\n",
    "  Args:\n",
    "    text: text to tokenize (string).\n",
    "    lowercase: whether to include lowercasing in preprocessing (boolean).\n",
    "    tokenizer: Python function to tokenize the text on.\n",
    "\n",
    "  Returns:\n",
    "    A list of strings (words).\n",
    "  \"\"\"\n",
    "  words = nltk.word_tokenize(text.decode('utf-8'))\n",
    "  if lowercase:\n",
    "    words = [w.lower() for w in words]\n",
    "  return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "PERFORMANCE_DATASET = 'gs://kaggle-model-experiments/resources/toxicity_q42017_test.tfrecord'\n",
    "LABEL_NAME_TEST_FILE = 'frac_neg' #Name of the label in the performance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_fn(tf_records_path, text_feature_name, label_name):\n",
    "                    \n",
    "  def load_tf_records_to_pandas(max_n_examples=None, random_filter_keep_rate=1.0):\n",
    "      '''Loads tf-records into a pandas dataframe.'''\n",
    "\n",
    "      if not max_n_examples:\n",
    "        max_n_examples = float('inf')\n",
    "\n",
    "      # Read TFRecord file\n",
    "      reader = tf.TFRecordReader()\n",
    "      filename_queue = tf.train.string_input_producer([tf_records_path], num_epochs=1)\n",
    "\n",
    "      _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "      # Define features\n",
    "      read_features = {\n",
    "          text_feature_name: tf.FixedLenFeature([], dtype=tf.string),\n",
    "          label_name: tf.FixedLenFeature([], dtype=tf.float32)\n",
    "      }\n",
    "\n",
    "      # Extract features from serialized data\n",
    "      read_data = tf.parse_single_example(serialized=serialized_example,\n",
    "                                          features=read_features)\n",
    "\n",
    "      # Read and print data:\n",
    "      sess = tf.InteractiveSession()\n",
    "\n",
    "      # Many tf.train functions use tf.train.QueueRunner,\n",
    "      # so we need to start it before we read.\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      sess.run(tf.local_variables_initializer())\n",
    "      sess.run(tf.tables_initializer())\n",
    "      tf.train.start_queue_runners(sess)\n",
    "\n",
    "      d = []\n",
    "      new_line = sess.run(read_data)\n",
    "      count = 0\n",
    "      while new_line:\n",
    "        if random.random() < random_filter_keep_rate:\n",
    "            d.append(new_line)\n",
    "            count += 1\n",
    "            if count >= max_n_examples:\n",
    "              break\n",
    "            if not(count % 100000):\n",
    "              print ('Loaded {} lines.'.format(count))\n",
    "        try:\n",
    "          new_line = sess.run(read_data)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          print ('End of file.')\n",
    "          break\n",
    "        \n",
    "      res = pd.DataFrame(d)\n",
    "      res[text_feature_name] = list(map(tokenizer, res[text_feature_name]))\n",
    "      \n",
    "      return res\n",
    "\n",
    "  return load_tf_records_to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mgoogle-cloud-pubsub 0.26.0 has requirement google-cloud-core<0.26dev,>=0.25.0, but you'll have google-cloud-core 0.28.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-gax 0.15.15 has requirement grpcio<1.6dev,>=1.0.2, but you'll have grpcio 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mapache-beam 2.1.1 has requirement httplib2<0.10,>=0.8, but you'll have httplib2 0.11.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mapache-beam 2.1.1 has requirement protobuf<=3.3.0,>=3.2.0, but you'll have protobuf 3.5.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mapache-beam 2.1.1 has requirement six<1.11,>=1.9, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorboard 1.8.0 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorboard 1.8.0 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-gpu 1.2.1 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-gpu 1.2.1 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.1.8 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.1.8 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogledatastore 7.0.1 has requirement httplib2<0.10,>=0.9.1, but you'll have httplib2 0.11.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q git+https://github.com/conversationai/unintended-ml-bias-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unintended_ml_bias import model_bias_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading it from it the unintended_ml_bias github.\n",
    "entire_test_bias_df = pd.read_csv(\n",
    "    pkg_resources.resource_stream(\"unintended_ml_bias\", \"eval_datasets/bias_madlibs_77k.csv\"))\n",
    "entire_test_bias_df['raw_text'] = entire_test_bias_df['Text']\n",
    "entire_test_bias_df['label'] = entire_test_bias_df['Label']\n",
    "entire_test_bias_df['label'] = list(map(lambda x: x=='BAD', entire_test_bias_df['label']))\n",
    "entire_test_bias_df = entire_test_bias_df[['raw_text', 'label']].copy()\n",
    "terms = [line.strip()\n",
    "         for line in pkg_resources.resource_stream(\"unintended_ml_bias\", \"bias_madlibs_data/adjectives_people.txt\")]\n",
    "model_bias_analysis.add_subgroup_columns_from_text(entire_test_bias_df, 'raw_text', terms)\n",
    "# Add preprocessing\n",
    "entire_test_bias_df['text'] = list(map(tokenizer, entire_test_bias_df['raw_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_bias(max_n_examples):\n",
    "    if max_n_examples:\n",
    "        res = entire_test_bias_df.sample(n=max_n_examples, random_state=2018)\n",
    "    else:\n",
    "        res = entire_test_bias_df\n",
    "    res = res.copy(deep=True)\n",
    "    res = res.rename(\n",
    "        columns={\n",
    "            'raw_text': TEXT_FEATURE_NAME\n",
    "        })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Running prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs.\n",
    "model_input_spec = {\n",
    "    TEXT_FEATURE_NAME: utils_cloudml.FeatureSpec.LIST_STRING} #library will use this automatically\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "SIZE_PERFORMANCE_DATA_SET = 10000\n",
    "\n",
    "# Pattern for path of tf_records\n",
    "TF_RECORD_PERFORMANCE_PATTERN = os.path.join(\n",
    "    'gs://kaggle-model-experiments/',\n",
    "    getpass.getuser(),\n",
    "    'tfrecords/test_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_fn is compatible with the `Dataset` class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/fprost/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "input_fn_performance = create_input_fn(PERFORMANCE_DATASET, TEXT_FEATURE_NAME, LABEL_NAME_TEST_FILE)\n",
    "dataset_performance = Dataset(input_fn_performance)\n",
    "dataset_performance.load_data(SIZE_PERFORMANCE_DATA_SET, random_filter_keep_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Model is compatible with the `Dataset` instance.\n",
      "INFO:tensorflow:Preparing train data: 0/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/fprost/anaconda2/lib/python2.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:state : QUEUED\n",
      "INFO:tensorflow:Waiting for prediction job to complete. Minutes elapsed: 0.0\n",
      "INFO:tensorflow:Waiting for prediction job to complete. Minutes elapsed: 2.5\n",
      "INFO:tensorflow:Waiting for prediction job to complete. Minutes elapsed: 5.0\n",
      "INFO:tensorflow:Prediction job completed.\n"
     ]
    }
   ],
   "source": [
    "dataset_performance.add_model_prediction_to_data(model, tf_record_path_pattern=TF_RECORD_PERFORMANCE_PATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "SIZE_PERFORMANCE_DATA_SET = None\n",
    "\n",
    "# Pattern for path of tf_records\n",
    "TF_RECORD_BIAS_PATTERN = os.path.join(\n",
    "    'gs://kaggle-model-experiments/',\n",
    "    getpass.getuser(),\n",
    "    'tfrecords/bias_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_fn is compatible with the `Dataset` class.\n"
     ]
    }
   ],
   "source": [
    "dataset_bias = Dataset(input_fn_bias)\n",
    "dataset_bias.load_data(SIZE_PERFORMANCE_DATA_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Model is compatible with the `Dataset` instance.\n",
      "INFO:tensorflow:Preparing train data: 0/76564\n",
      "INFO:tensorflow:Preparing train data: 10000/76564\n",
      "INFO:tensorflow:Preparing train data: 20000/76564\n",
      "INFO:tensorflow:Preparing train data: 30000/76564\n",
      "INFO:tensorflow:Preparing train data: 40000/76564\n",
      "INFO:tensorflow:Preparing train data: 50000/76564\n",
      "INFO:tensorflow:Preparing train data: 60000/76564\n",
      "INFO:tensorflow:Preparing train data: 70000/76564\n",
      "INFO:tensorflow:state : QUEUED\n",
      "INFO:tensorflow:Waiting for prediction job to complete. Minutes elapsed: 0.0\n",
      "INFO:tensorflow:Waiting for prediction job to complete. Minutes elapsed: 2.5\n",
      "INFO:tensorflow:Waiting for prediction job to complete. Minutes elapsed: 5.0\n",
      "INFO:tensorflow:Prediction job completed.\n"
     ]
    }
   ],
   "source": [
    "dataset_bias.add_model_prediction_to_data(model, tf_record_path_pattern=TF_RECORD_BIAS_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the table to match the required format.\n",
    "test_performance_df = dataset_performance.show_data()\n",
    "test_performance_df = test_performance_df.rename(\n",
    "    columns={\n",
    "        TEXT_FEATURE_NAME: 'raw_text',\n",
    "        LABEL_NAME_TEST_FILE: 'label'\n",
    "    })\n",
    "test_performance_df['label'] = list(map(lambda x :bool(round(x)), list(test_performance_df['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bias_df = dataset_bias.show_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1530641283264,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "Y7R4heIB5GaV",
    "outputId": "e8e0c3bc-96d8-4635-865a-275052054df8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tf_gru_attention:v_20180823_133625</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[``, the, tank, losses, extremely, biased, the...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.427523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[sandifer, ,, i, 'm, going, buy, my, way, back...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.320056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[support, per, nom, ., talk]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.290629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[``, we, do, n't, keep, non-free, material, ju...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.331023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[unblock, and, thanks, ,]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.289773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  label  \\\n",
       "0  [``, the, tank, losses, extremely, biased, the...  False   \n",
       "1  [sandifer, ,, i, 'm, going, buy, my, way, back...   True   \n",
       "2                       [support, per, nom, ., talk]  False   \n",
       "3  [``, we, do, n't, keep, non-free, material, ju...  False   \n",
       "4                          [unblock, and, thanks, ,]  False   \n",
       "\n",
       "   tf_gru_attention:v_20180823_133625  \n",
       "0                            0.427523  \n",
       "1                            0.320056  \n",
       "2                            0.290629  \n",
       "3                            0.331023  \n",
       "4                            0.289773  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1530641286091,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "Ln2BXOg4Q6GP",
    "outputId": "bb5288e8-9f10-4796-b36e-42f5c02cb148"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "      <th>lesbian</th>\n",
       "      <th>gay</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>transgender</th>\n",
       "      <th>trans</th>\n",
       "      <th>queer</th>\n",
       "      <th>lgbt</th>\n",
       "      <th>lgbtq</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>teenage</th>\n",
       "      <th>millenial</th>\n",
       "      <th>middle aged</th>\n",
       "      <th>elderly</th>\n",
       "      <th>blind</th>\n",
       "      <th>deaf</th>\n",
       "      <th>paralyzed</th>\n",
       "      <th>text</th>\n",
       "      <th>tf_gru_attention:v_20180823_133625</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>murder american</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[murder, american]</td>\n",
       "      <td>0.438511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>respect trans</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[respect, trans]</td>\n",
       "      <td>0.447293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>respect homosexual</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[respect, homosexual]</td>\n",
       "      <td>0.428770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hug mexican</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[hug, mexican]</td>\n",
       "      <td>0.444693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kill sikh</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[kill, sikh]</td>\n",
       "      <td>0.429989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_text  label  lesbian    gay  bisexual  transgender  trans  \\\n",
       "0     murder american   True    False  False     False        False  False   \n",
       "1       respect trans  False    False  False     False        False   True   \n",
       "2  respect homosexual  False    False  False     False        False  False   \n",
       "3         hug mexican  False    False  False     False        False  False   \n",
       "4           kill sikh   True    False  False     False        False  False   \n",
       "\n",
       "   queer   lgbt  lgbtq                 ...                  younger  teenage  \\\n",
       "0  False  False  False                 ...                    False    False   \n",
       "1  False  False  False                 ...                    False    False   \n",
       "2  False  False  False                 ...                    False    False   \n",
       "3  False  False  False                 ...                    False    False   \n",
       "4  False  False  False                 ...                    False    False   \n",
       "\n",
       "   millenial  middle aged  elderly  blind   deaf  paralyzed  \\\n",
       "0      False        False    False  False  False      False   \n",
       "1      False        False    False  False  False      False   \n",
       "2      False        False    False  False  False      False   \n",
       "3      False        False    False  False  False      False   \n",
       "4      False        False    False  False  False      False   \n",
       "\n",
       "                    text  tf_gru_attention:v_20180823_133625  \n",
       "0     [murder, american]                            0.438511  \n",
       "1       [respect, trans]                            0.447293  \n",
       "2  [respect, homosexual]                            0.428770  \n",
       "3         [hug, mexican]                            0.444693  \n",
       "4           [kill, sikh]                            0.429989  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8m8QI4qEjtcY"
   },
   "source": [
    "# Part 3: Run evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FAMILIES = [MODEL_NAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhwSHsMtO9fF"
   },
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our performance data is in DataFrame df, with columns:\n",
    "\n",
    "text: Full text of the comment.\n",
    "label: True if the comment is Toxic, False otherwise.\n",
    "< model name >: One column per model, cells contain the score from that model.\n",
    "You can run the analysis below on any data in this format. Subgroup labels can be generated via words in the text as done above, or come from human labels if you have them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XUZYCq-6N8MK"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1530641399913,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "yc8SWZbqMwA4",
    "outputId": "6e9399b8-ce22-42bb-c318-959bae73f6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for model tf_gru_attention:v_20180823_133625: 0.406235508997\n"
     ]
    }
   ],
   "source": [
    "for model_family in MODEL_FAMILIES:\n",
    "  auc_list = []\n",
    "  for model in model_family:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        test_performance_df['label'],\n",
    "        test_performance_df[model])\n",
    "    auc_list.append(metrics.auc(fpr, tpr))\n",
    "  print ('Auc for model {}: {}'.format(model, np.mean(auc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTrKsfIcxoBh"
   },
   "source": [
    "## Unintended Bias Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3ZJSKY8FHFH"
   },
   "source": [
    "### Data Format\n",
    "At this point, our bias data is in DataFrame df, with columns:\n",
    "\n",
    "*   label: True if the comment is Toxic, False otherwise.\n",
    "*   < model name >: One column per model, cells contain the score from that model.\n",
    "*   < subgroup >: One column per identity, True if the comment mentions this identity.\n",
    "\n",
    "You can run the analysis below on any data in this format. Subgroup labels can be \n",
    "generated via words in the text as done above, or come from human labels if you have them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPXk78apx2-Z"
   },
   "source": [
    "### Pinned AUC\n",
    "Pinned AUC measures the extent of unintended bias of a real-value score function\n",
    "by measuring each sub-group's divergence from the general distribution.\n",
    "\n",
    "Let $D$ represent the full data set and $D_g$ be the set of examples in subgroup\n",
    "$g$. Then:\n",
    "\n",
    "\n",
    "$$ Pinned \\ dataset \\ for \\ group \\ g = pD_g = s(D_g) + s(D), |s(D_g)| = |s(D)| $$\n",
    "\n",
    "$$ Pinned \\ AUC \\ for \\ group \\ g = pAUC_g = AUC(pD_g) $$\n",
    "\n",
    "$$ Pinned \\ AUC \\ Squared \\ Equality \\ Difference = \\Sigma_{g \\in G}(AUC - pAUC_g)^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65U3PzABPiE6"
   },
   "source": [
    "### Pinned AUC Equality Difference\n",
    "The table below shows the pinned AUC equality difference for each model family.\n",
    "Lower scores (lighter red) represent more similarity between each group's pinned AUC, which means\n",
    "less unintended bias.\n",
    "\n",
    "On this set, the wiki_debias_cnn model demonstrates least unintended bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"red\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1019,
     "status": "error",
     "timestamp": 1530641407221,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "W8p5iHW2RZmN",
    "outputId": "e4b3f09b-ad81-48dc-b9ad-ef2a77233044",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_073ca952_b828_11e8_9321_dc4a3e9983aerow0_col1 {\n",
       "            background-color:  #ffe5e5;\n",
       "        }</style>  \n",
       "<table id=\"T_073ca952_b828_11e8_9321_dc4a3e9983ae\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >model_family</th> \n",
       "        <th class=\"col_heading level0 col1\" >pinned_auc_equality_difference</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_073ca952_b828_11e8_9321_dc4a3e9983aelevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_073ca952_b828_11e8_9321_dc4a3e9983aerow0_col0\" class=\"data row0 col0\" >tf_gru_attention:v_20180823_133625</td> \n",
       "        <td id=\"T_073ca952_b828_11e8_9321_dc4a3e9983aerow0_col1\" class=\"data row0 col1\" >0.00865119</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f02240c9810>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_diff = model_bias_analysis.per_subgroup_auc_diff_from_overall(\n",
    "    test_bias_df, terms, MODEL_FAMILIES, squared_error=True, normed_auc=True)\n",
    "# sort to guarantee determi7nistic output\n",
    "eq_diff.sort_values(by=['model_family'], inplace=True)\n",
    "eq_diff.reset_index(drop=True, inplace=True)\n",
    "eq_diff.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bEC5cAsyC05"
   },
   "source": [
    "### Pinned AUC Graphs\n",
    "The graphs below show per-group Pinned AUC for each subgroup and each model. Each\n",
    "identity group shows 3 points, each representing the pinned AUC for one training \n",
    "version of the model. More consistency among the values represents less unintended bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1552,
     "status": "ok",
     "timestamp": 1530303491427,
     "user": {
      "displayName": "Flavien Prost",
      "photoUrl": "//lh5.googleusercontent.com/-2GvWuP8dy24/AAAAAAAAAAI/AAAAAAAAAHI/aCatYKxJMXQ/s50-c-k-no/photo.jpg",
      "userId": "100080410554240838905"
     },
     "user_tz": 240
    },
    "id": "QqMmPTreOCPf",
    "outputId": "39cc5e70-b76d-413e-b286-e25f7a68e732"
   },
   "outputs": [],
   "source": [
    "pinned_auc_results = model_bias_analysis.per_subgroup_aucs(test_bias_df, terms, MODEL_FAMILIES, 'label')\n",
    "for family in MODEL_FAMILIES:\n",
    "  name = model_bias_analysis.model_family_name(family)\n",
    "  model_bias_analysis.per_subgroup_scatterplots(\n",
    "      pinned_auc_results,\n",
    "      'subgroup',\n",
    "      name + '_aucs',\n",
    "      name + ' Pinned AUC',\n",
    "      y_lim=(0., 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "jigsaw-evaluation-pipeline.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
